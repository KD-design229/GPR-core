{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3db5adff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T06:03:50.326055Z",
     "iopub.status.busy": "2025-11-15T06:03:50.325793Z",
     "iopub.status.idle": "2025-11-15T06:05:49.100834Z",
     "shell.execute_reply": "2025-11-15T06:05:49.100070Z"
    },
    "papermill": {
     "duration": 118.783475,
     "end_time": "2025-11-15T06:05:49.102520",
     "exception": false,
     "start_time": "2025-11-15T06:03:50.319045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\r\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mæ­£åœ¨æ¸…ç†è¡çªçš„åŒ…...\n",
      "Found existing installation: numpy 2.2.6\r\n",
      "Uninstalling numpy-2.2.6:\r\n",
      "  Successfully uninstalled numpy-2.2.6\r\n",
      "Found existing installation: scipy 1.15.3\r\n",
      "Uninstalling scipy-1.15.3:\r\n",
      "  Successfully uninstalled scipy-1.15.3\r\n",
      "Found existing installation: opencv-python 4.12.0.88\r\n",
      "Uninstalling opencv-python-4.12.0.88:\r\n",
      "  Successfully uninstalled opencv-python-4.12.0.88\r\n",
      "Found existing installation: opencv-contrib-python 4.12.0.88\r\n",
      "Uninstalling opencv-contrib-python-4.12.0.88:\r\n",
      "  Successfully uninstalled opencv-contrib-python-4.12.0.88\r\n",
      "Found existing installation: opencv-python-headless 4.12.0.88\r\n",
      "Uninstalling opencv-python-headless-4.12.0.88:\r\n",
      "  Successfully uninstalled opencv-python-headless-4.12.0.88\r\n",
      "\n",
      "å®‰è£å…¼å®¹ç‰ˆæœ¬çš„æ ¸å¿ƒåº«...\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ä¿®å¤ä¾èµ–å†²çª\n",
    "# å®‰è£…å¹¶å¯¼å…¥ - é”å®šå…¼å®¹ç‰ˆæœ¬é¿å… Kaggle ç¯å¢ƒä¾èµ–å†²çª\n",
    "!pip install -q tensorboardX albumentations thop\n",
    "# ===== ä¿®å¤ Kaggle 2025 ç¯å¢ƒå…¼å®¹æ€§é—®é¢˜ =====\n",
    "# é—®é¢˜ï¼šKaggle å‡çº§åˆ° NumPy 2.x å¯¼è‡´ SciPy/Seaborn/OpenCV å´©æºƒ\n",
    "# è§£å†³ï¼šé”å®šåˆ° 2024 å¹´ç¨³å®šçš„ç‰ˆæœ¬ç»„åˆ\n",
    "\n",
    "# é¦–å…ˆï¼ŒæŒ‰ç…§åŸæ„åœ–è§£é™¤å®‰è£è¡çªçš„å¥—ä»¶\n",
    "print(\"æ­£åœ¨æ¸…ç†è¡çªçš„åŒ…...\")\n",
    "!pip uninstall -y numpy scipy opencv-python opencv-contrib-python opencv-python-headless 2>/dev/null || true\n",
    "\n",
    "# æ¥è‘—ï¼Œåœ¨å–®ä¸€æŒ‡ä»¤ä¸­å®‰è£æ‰€æœ‰å¿…è¦çš„å‡½å¼åº«\n",
    "# é€™èƒ½è®“ pip ä¸€æ¬¡æ€§è§£æ±ºæ‰€æœ‰ä¾è³´é—œä¿‚ï¼Œä¸¦éµå¾ªç‰ˆæœ¬é–å®š\n",
    "print(\"\\nå®‰è£å…¼å®¹ç‰ˆæœ¬çš„æ ¸å¿ƒåº«...\")\n",
    "!pip install --quiet \\\n",
    "    numpy==1.26.4 \\\n",
    "    scipy==1.11.4 \\\n",
    "    matplotlib==3.7.5 \\\n",
    "    opencv-python==4.8.1.78 \\\n",
    "    albumentations \\\n",
    "    tensorboardX \\\n",
    "    thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c66189f0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-15T06:05:49.156472Z",
     "iopub.status.busy": "2025-11-15T06:05:49.155697Z",
     "iopub.status.idle": "2025-11-15T06:06:19.467040Z",
     "shell.execute_reply": "2025-11-15T06:06:19.466193Z"
    },
    "papermill": {
     "duration": 30.339388,
     "end_time": "2025-11-15T06:06:19.468601",
     "exception": false,
     "start_time": "2025-11-15T06:05:49.129213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "from thop import profile\n",
    "from copy import deepcopy\n",
    "from torch.optim import Adam\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import v2\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import default_collate \n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, classification_report\n",
    "# ...\n",
    "# è®¾ç½®æ—¥å¿—è®°å½•\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb14cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T06:06:19.522004Z",
     "iopub.status.busy": "2025-11-15T06:06:19.521326Z",
     "iopub.status.idle": "2025-11-15T06:06:19.527909Z",
     "shell.execute_reply": "2025-11-15T06:06:19.527185Z"
    },
    "papermill": {
     "duration": 0.034306,
     "end_time": "2025-11-15T06:06:19.529172",
     "exception": false,
     "start_time": "2025-11-15T06:06:19.494866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KaggleConfig:\n",
    "    def __init__(self):\n",
    "        # --- è·¯å¾„è®¾ç½® (è¯·æ ¹æ®æ‚¨çš„Kaggleæ•°æ®é›†åç§°ä¿®æ”¹) ---\n",
    "        # å‡è®¾æ‚¨çš„Kaggleæ•°æ®é›†åœ°å€æ˜¯ /kaggle/input/your-dataset-name\n",
    "        # æ‚¨éœ€è¦å°†ä¸‹é¢çš„ 'your-dataset-slug' æ›¿æ¢ä¸ºæ‚¨çš„æ•°æ®é›†çš„å®é™…åç§°\n",
    "        \n",
    "        \n",
    "        self.train_path = '/kaggle/input/data-base/Dataset_base_split_new/train'\n",
    "        self.val_path = '/kaggle/input/data-base/Dataset_base_split_newval'\n",
    "        self.test_path = '/kaggle/input/data-base-test/test'\n",
    "        self.save_path = '/kaggle/working/' # æ¨¡å‹å’Œè¾“å‡ºæ–‡ä»¶å°†ä¿å­˜åœ¨è¿™é‡Œ\n",
    "\n",
    "        # --- è®­ç»ƒå‚æ•° ---\n",
    "        self.train_batch_size = 64\n",
    "        self.val_batch_size = 64\n",
    "        self.test_batch_size = 128\n",
    "        self.num_epochs = 200\n",
    "        self.cuda_no = 0\n",
    "        \n",
    "        # --- KæŠ˜äº¤å‰éªŒè¯å‚æ•° ---\n",
    "        self.n_folds = 5  # KæŠ˜äº¤å‰éªŒè¯çš„æŠ˜æ•°\n",
    "        self.current_fold = 0  # å½“å‰æŠ˜ç´¢å¼•\n",
    "        \n",
    "        # ğŸ†• æ§åˆ¶è¿è¡Œå“ªäº›fold\n",
    "        self.start_fold = 4  # ä»ç¬¬4æŠ˜å¼€å§‹ï¼ˆç´¢å¼•ä»0å¼€å§‹ï¼Œæ‰€ä»¥4è¡¨ç¤ºç¬¬5æŠ˜ï¼Œå³æœ€åä¸€æŠ˜ï¼‰\n",
    "        self.end_fold = 5    # åˆ°ç¬¬5æŠ˜ç»“æŸï¼ˆä¸åŒ…å«ï¼Œæ‰€ä»¥åªè¿è¡Œfold 4ï¼‰\n",
    "        \n",
    "        # --- æ¨¡å‹å’Œä¼˜åŒ–å™¨å‚æ•° ---\n",
    "        self.encoder = 'tf_efficientnetv2_b0'  # ğŸ”¥ ä¿®æ­£ä¸º resnet50ï¼ˆä¸æ‚¨çš„éœ€æ±‚ä¸€è‡´ï¼‰\n",
    "        self.classnum = 8        # æ‚¨çš„æ€»ç±»åˆ«æ•°\n",
    "        self.LR_clf = 1e-5       # ğŸ”¥ ä¿®æ”¹ä¸º 5e-5\n",
    "        self.LR_head = 1e-3     # <-- æ–°å¢ï¼šç”¨äºé˜¶æ®µä¸€çš„å­¦ä¹ ç‡ï¼Œè¦å¤§å¾—å¤š\n",
    "        self.WE_dec = 0.06\n",
    "        self.min_lr = 1e-6\n",
    "\n",
    "        #å­¦ä¹ ç‡ç­–ç•¥\n",
    "        # ReduceLROnPlateau å‚æ•°ï¼ˆä»…åœ¨ lr_scheduler == \"plateau\" æ—¶ç”Ÿæ•ˆï¼‰\n",
    "        self.lr_scheduler = \"plateau\"  # æƒ³ç”¨ä½™å¼¦é€€ç«å°±æ”¹ä¸º \"cosine\"\n",
    "        self.plateau_factor = 0.5   # æ¯æ¬¡é™ LR çš„å€æ•°\n",
    "        self.plateau_patience = 5   # è¿ç»­å¤šå°‘ä¸ª epoch éªŒè¯æŸå¤±ä¸ä¸‹é™æ‰é™ LR\n",
    "        # ä½™å¼¦çš„ T_max è®¾ç½®ï¼ˆå¯æŒ‰é˜¶æ®µåˆ†åˆ«è®¾ç½®ï¼‰\n",
    "        self.stage1_tmax = 15\n",
    "        \n",
    "        # --- æ–°å¢å‚æ•° ---\n",
    "        self.use_hybrid_mix = 0 \n",
    "        self.aug_methon = 1\n",
    "        self.label_smoothing = 0.00 # æ ‡ç­¾å¹³æ»‘çš„å¼ºåº¦ï¼Œ0.1æ˜¯ä¸€ä¸ªå¸¸ç”¨å€¼\n",
    "        self.focal_loss_gamma = 2.0  # æ·»åŠ  gamma å‚æ•°ï¼Œ2.0 æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·å§‹å€¼\n",
    "        self.fold = 0\n",
    "        self.dropout_rate = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99447989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T06:06:19.581343Z",
     "iopub.status.busy": "2025-11-15T06:06:19.581092Z",
     "iopub.status.idle": "2025-11-15T06:06:19.588419Z",
     "shell.execute_reply": "2025-11-15T06:06:19.587886Z"
    },
    "papermill": {
     "duration": 0.034822,
     "end_time": "2025-11-15T06:06:19.589381",
     "exception": false,
     "start_time": "2025-11-15T06:06:19.554559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss çš„ PyTorch å®ç°ã€‚\n",
    "    è¿™ä¸ªæŸå¤±å‡½æ•°è¢«è®¾è®¡ç”¨æ¥è§£å†³ç±»åˆ«ä¸å¹³è¡¡å’Œéš¾æ˜“æ ·æœ¬ä¸å¹³è¡¡çš„é—®é¢˜ã€‚\n",
    "    å®ƒé€šè¿‡ä¸€ä¸ªåŠ¨æ€ç¼©æ”¾å› å­æ¥é™ä½â€œç®€å•â€æ ·æœ¬å¯¹æŸå¤±çš„è´¡çŒ®ï¼Œ\n",
    "    ä»è€Œè®©æ¨¡å‹æ›´åŠ ä¸“æ³¨äºå­¦ä¹ é‚£äº›â€œå›°éš¾â€çš„æ ·æœ¬ã€‚\n",
    "\n",
    "    å…¬å¼: FL(p_t) = -Î±_t * (1 - p_t)^Î³ * log(p_t)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ– Focal Loss.\n",
    "        Args:\n",
    "            alpha (Tensor, optional): ä¸€ä¸ªä¸ç±»åˆ«æ•°é‡ç›¸åŒé•¿åº¦çš„å¼ é‡ï¼Œç”¨äºä¸ºæ¯ä¸ªç±»åˆ«åˆ†é…æƒé‡ã€‚\n",
    "                                      è¿™ä¸åŠ æƒäº¤å‰ç†µä¸­çš„ 'weight' å‚æ•°ä½œç”¨ç›¸åŒã€‚\n",
    "                                      é»˜è®¤å€¼: None (æ‰€æœ‰ç±»åˆ«æƒé‡ä¸º1)ã€‚\n",
    "            gamma (float, optional): èšç„¦å‚æ•° (Focusing Parameter)ã€‚\n",
    "                                     è¯¥å€¼è¶Šå¤§ï¼Œæ¨¡å‹å°±è¶Šä¼šä¸“æ³¨äºå›°éš¾æ ·æœ¬ã€‚\n",
    "                                     è®ºæ–‡ä¸­æ¨èçš„é»˜è®¤å€¼ä¸º 2.0ã€‚\n",
    "            reduction (str, optional): æŒ‡å®šå¦‚ä½•å¯¹æ‰¹æ¬¡çš„æŸå¤±è¿›è¡Œèšåˆã€‚\n",
    "                                       å¯é€‰å€¼: 'mean', 'sum', 'none'ã€‚\n",
    "                                       é»˜è®¤å€¼: 'mean'ã€‚\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        # alpha å‚æ•°ç”¨äºå¹³è¡¡ç±»åˆ«é‡è¦æ€§ï¼Œå¯ä»¥æ˜¯ None æˆ–è€…ä¸€ä¸ª Tensor\n",
    "        # å¦‚æœæ˜¯ Tensorï¼Œæˆ‘ä»¬ä¼šç¡®ä¿å®ƒåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š\n",
    "        if alpha is not None:\n",
    "            if not isinstance(alpha, torch.Tensor):\n",
    "                alpha = torch.tensor(alpha)\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # gamma æ˜¯èšç„¦å‚æ•°ï¼Œç”¨äºè°ƒèŠ‚éš¾æ˜“æ ·æœ¬çš„æƒé‡\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # reduction æŒ‡å®šæœ€ç»ˆæŸå¤±çš„è®¡ç®—æ–¹å¼\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        è®¡ç®— Focal Loss çš„å‰å‘ä¼ æ’­ã€‚\n",
    "        Args:\n",
    "            inputs (Tensor): æ¨¡å‹çš„åŸå§‹è¾“å‡º (logits)ï¼Œå½¢çŠ¶ä¸º [N, C]ï¼Œ\n",
    "                             å…¶ä¸­ N æ˜¯æ‰¹æ¬¡å¤§å°, C æ˜¯ç±»åˆ«æ•°ã€‚\n",
    "            targets (Tensor): çœŸå®çš„ç±»åˆ«æ ‡ç­¾ï¼Œå½¢çŠ¶ä¸º [N]ã€‚\n",
    "        Returns:\n",
    "            Tensor: è®¡ç®—å‡ºçš„ Focal Lossã€‚\n",
    "        \"\"\"\n",
    "        # ç¡®ä¿ alpha æƒé‡å¼ é‡å’Œè¾“å…¥åœ¨åŒä¸€ä¸ªè®¾å¤‡ä¸Š (CPU æˆ– GPU)\n",
    "        if self.alpha is not None and self.alpha.device != inputs.device:\n",
    "            self.alpha = self.alpha.to(inputs.device)\n",
    "\n",
    "        # æ­¥éª¤ 1: è®¡ç®—æ ‡å‡†çš„äº¤å‰ç†µæŸå¤±ï¼Œä½†ä¸è¿›è¡Œä»»ä½•èšåˆ (reduction='none')\n",
    "        #         è¿™æ ·æˆ‘ä»¬å¯ä»¥å¾—åˆ°æ‰¹æ¬¡ä¸­æ¯ä¸ªæ ·æœ¬çš„ç‹¬ç«‹æŸå¤±å€¼ã€‚\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "\n",
    "        # æ­¥éª¤ 2: ä»äº¤å‰ç†µæŸå¤±ä¸­è®¡ç®—å‡ºæ¨¡å‹å¯¹æ­£ç¡®ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡ p_t\n",
    "        #         å…¬å¼: p_t = exp(-ce_loss)\n",
    "        #         è¿™ä¸ªæŠ€å·§å¯ä»¥é¿å…ç›´æ¥æ“ä½œ softmax çš„è¾“å‡ºï¼Œæ•°å€¼ä¸Šæ›´ç¨³å®šã€‚\n",
    "        pt = torch.exp(-ce_loss)\n",
    "\n",
    "        # æ­¥éª¤ 3: è®¡ç®— Focal Loss çš„æ ¸å¿ƒéƒ¨åˆ†â€”â€”åŠ¨æ€ç¼©æ”¾å› å­\n",
    "        #         å…¬å¼: (1 - p_t)^Î³\n",
    "        #         è¿™ä¸ªå› å­ä¼šæ ¹æ®é¢„æµ‹æ¦‚ç‡ pt çš„å¤§å°æ¥åŠ¨æ€è°ƒæ•´æŸå¤±çš„æƒé‡ã€‚\n",
    "        #         å¦‚æœ pt å¾ˆå¤§ (æ¥è¿‘1ï¼Œç®€å•æ ·æœ¬)ï¼Œè¿™ä¸ªå› å­å°±æ¥è¿‘0ï¼ŒæŸå¤±è¢«å¤§å¹…å‰Šå¼±ã€‚\n",
    "        #         å¦‚æœ pt å¾ˆå° (æ¥è¿‘0ï¼Œå›°éš¾æ ·æœ¬)ï¼Œè¿™ä¸ªå› å­å°±æ¥è¿‘1ï¼ŒæŸå¤±åŸºæœ¬ä¿æŒä¸å˜ã€‚\n",
    "        focal_term = (1 - pt) ** self.gamma\n",
    "\n",
    "        # æ­¥éª¤ 4: è®¡ç®—æœ€ç»ˆçš„ Focal Loss\n",
    "        #         é¦–å…ˆå°†åŠ¨æ€ç¼©æ”¾å› å­ä¸åŸå§‹çš„äº¤å‰ç†µæŸå¤±ç›¸ä¹˜ã€‚\n",
    "        loss = focal_term * ce_loss\n",
    "\n",
    "        # æ­¥éª¤ 5: (å¯é€‰) å¦‚æœæä¾›äº† alpha æƒé‡ï¼Œåˆ™å†ä¹˜ä¸Šå¯¹åº”ç±»åˆ«çš„æƒé‡\n",
    "        if self.alpha is not None:\n",
    "            # self.alpha[targets] ä¼šæ ¹æ® targets ä¸­çš„æ ‡ç­¾ç´¢å¼•ï¼Œ\n",
    "            # ä» alpha æƒé‡å¼ é‡ä¸­å–å‡ºæ¯ä¸ªæ ·æœ¬å¯¹åº”çš„æƒé‡ã€‚\n",
    "            alpha_t = self.alpha[targets]\n",
    "            loss = alpha_t * loss\n",
    "\n",
    "        # æ­¥éª¤ 6: æ ¹æ®æŒ‡å®šçš„ reduction å‚æ•°å¯¹æœ€ç»ˆçš„æŸå¤±è¿›è¡Œèšåˆ\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "718fbda4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T06:06:19.640445Z",
     "iopub.status.busy": "2025-11-15T06:06:19.640258Z",
     "iopub.status.idle": "2025-11-15T06:06:19.655328Z",
     "shell.execute_reply": "2025-11-15T06:06:19.654689Z"
    },
    "papermill": {
     "duration": 0.041916,
     "end_time": "2025-11-15T06:06:19.656347",
     "exception": false,
     "start_time": "2025-11-15T06:06:19.614431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "def count_parameters(model):\n",
    "    \"\"\"Counts the number of trainable parameters in a model.\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "def mean_and_std(paths):\n",
    "    print('Calculating mean and std of training set for data normalization.')\n",
    "    bgr_means, bgr_stds = [], []\n",
    "\n",
    "    for img_path in tqdm(paths):\n",
    "        img = cv2.imread(img_path)\n",
    "        channel_means, channel_stds = cv2.meanStdDev(img)[:2]\n",
    "        bgr_means.append(channel_means.reshape(3))\n",
    "        bgr_stds.append(channel_stds.reshape(3))\n",
    "\n",
    "    global_mean = np.mean(bgr_means, axis=0)[::-1] / 255.0\n",
    "    global_std = np.mean(bgr_stds, axis=0)[::-1] / 255.0\n",
    "\n",
    "    print(f\"Mean (RGB): {global_mean.tolist()}\")\n",
    "    print(f\"Std  (RGB): {global_std.tolist()}\")\n",
    "    return global_mean, global_std\n",
    "\n",
    "def save_metrics_to_excel(file_name, epoch, encoder_lr=None, loss=None, accuracy=None,\n",
    "                         precision=None, recall=None, f1=None, f1_macro=None, auc_macro=None,\n",
    "                         auc_weighted=None, confusion_matrix=None, **kwargs):\n",
    "    # ğŸ†• encoder_lr ä½œä¸ºç¬¬ä¸€åˆ—ï¼Œç”¨äºè¿½è¸ªå®éªŒé…ç½®\n",
    "    data = {\n",
    "        'encoder_lr': [encoder_lr],  # ğŸ†• æ–°å¢: è®°å½• run_id (ä¾‹å¦‚ \"convnext_tiny_lr_3e-5\")\n",
    "        'Epoch': [epoch], \n",
    "        'Loss': [loss], \n",
    "        'Accuracy': [accuracy], \n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall], \n",
    "        'F1_weighted': [f1], \n",
    "        'F1_macro': [f1_macro], \n",
    "        'AUC_macro': [auc_macro], \n",
    "        'AUC_weighted': [auc_weighted]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # åœ¨Kaggleç¯å¢ƒä¸­ï¼Œç›´æ¥ä½¿ç”¨save_path\n",
    "    args = KaggleConfig()\n",
    "    file_path = os.path.join(args.save_path, file_name)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        df.to_excel(file_path, index=False, sheet_name='Sheet1')\n",
    "    else:\n",
    "        with pd.ExcelWriter(file_path, mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:\n",
    "            if 'Sheet1' in writer.sheets:\n",
    "                 start_row = writer.sheets['Sheet1'].max_row\n",
    "                 df.to_excel(writer, sheet_name='Sheet1', index=False, header=False, startrow=start_row)\n",
    "            else:\n",
    "                 df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "def cm_to_figure(cm):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix')\n",
    "    buf = BytesIO()\n",
    "    fig.savefig(buf, format='png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    image = np.frombuffer(buf.getvalue(), dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image.transpose(2, 0, 1)\n",
    "\n",
    "def plot_history_curves(history, save_dir):\n",
    "    \"\"\"ç»˜åˆ¶å¹¶ä¿å­˜è®­ç»ƒå’ŒéªŒè¯çš„æŸå¤±ä¸å‡†ç¡®ç‡æ›²çº¿å›¾ã€‚\"\"\"\n",
    "    # æ£€æŸ¥historyå­—å…¸ä¸­æ˜¯å¦åŒ…å«æ‰€éœ€çš„æ‰€æœ‰é”®\n",
    "    required_keys = ['train_loss', 'val_loss', 'train_acc', 'val_acc']\n",
    "    if not all(key in history for key in required_keys):\n",
    "        print(\"Warning: History dictionary is missing one or more required keys for plotting. Skipping plot.\")\n",
    "        return\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    fig.suptitle('Training & Validation History', fontsize=16)\n",
    "\n",
    "    # ç¡®ä¿æ‰€æœ‰åˆ—è¡¨é•¿åº¦ä¸€è‡´ï¼Œä»¥æœ€çŸ­çš„ä¸ºå‡†\n",
    "    min_epochs = len(history['train_loss'])\n",
    "    epochs_range = range(min_epochs)\n",
    "\n",
    "    # ç»˜åˆ¶æŸå¤±æ›²çº¿\n",
    "    ax1.plot(epochs_range, history['train_loss'][:min_epochs], 'o-', label='Train Loss')\n",
    "    ax1.plot(epochs_range, history['val_loss'][:min_epochs], 'o-', label='Validation Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.set_title('Loss vs. Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿\n",
    "    ax2.plot(epochs_range, history['train_acc'][:min_epochs], 'o-', label='Train Accuracy')\n",
    "    ax2.plot(epochs_range, history['val_acc'][:min_epochs], 'o-', label='Validation Accuracy')\n",
    "    ax2.legend(loc='lower right')\n",
    "    ax2.set_title('Accuracy vs. Epochs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "\n",
    "    # ä¿å­˜å›¾ç‰‡\n",
    "    save_path = os.path.join(save_dir, 'history_curves.png')\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"âœ… Training history curves plot saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31770edb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T06:06:19.708632Z",
     "iopub.status.busy": "2025-11-15T06:06:19.708383Z",
     "iopub.status.idle": "2025-11-15T06:06:19.730520Z",
     "shell.execute_reply": "2025-11-15T06:06:19.729990Z"
    },
    "papermill": {
     "duration": 0.049552,
     "end_time": "2025-11-15T06:06:19.731512",
     "exception": false,
     "start_time": "2025-11-15T06:06:19.681960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. ä¸ºè®­ç»ƒé›†å®šä¹‰çš„æœ€ç»ˆå¢å¼ºæµæ°´çº¿ (ç²¾ç¡®å¤ç°ä½ çš„ç­‰æ¯”ä¾‹æ”¾å¤§ç­–ç•¥)\n",
    "# --- Hybrid Mix å®šä¹‰ ---\n",
    "args_for_mix = KaggleConfig() # è·å–ç±»åˆ«æ•°\n",
    "cutmix = v2.CutMix(num_classes=args_for_mix.classnum,alpha=0.8)\n",
    "mixup = v2.MixUp(num_classes=args_for_mix.classnum,alpha=0.8)\n",
    "cutmix_or_mixup = v2.RandomChoice([cutmix, mixup], p =[0.7,0.3])\n",
    "\n",
    "# --- Collate Function å®šä¹‰ ---\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    ä¸€ä¸ªæ›´å¥å£®çš„collate_fnï¼Œç”¨äºå¤„ç†åŒ…å«é¢å¤–ä¿¡æ¯ï¼ˆå¦‚æ–‡ä»¶åï¼‰çš„æ•°æ®ã€‚\n",
    "    \"\"\"\n",
    "    # 1. å…ˆç”¨PyTorché»˜è®¤çš„æ–¹å¼å°†ä¸€æ‰¹æ•°æ®æ‰“åŒ…ã€‚\n",
    "    # å¯¹äºæˆ‘ä»¬è¿”å› (æ–‡ä»¶å, å›¾åƒ, æ ‡ç­¾) çš„æ•°æ®é›†ï¼Œè¿™é‡Œä¼šå¾—åˆ°ä¸‰ä¸ªç‹¬ç«‹çš„æ‰¹æ¬¡ã€‚\n",
    "    filenames, images, targets = default_collate(batch)\n",
    "    \n",
    "    # 2. åªæŠŠå›¾åƒå’Œæ ‡ç­¾ä¼ å…¥CutMix/MixUpè¿›è¡Œå¤„ç†\n",
    "    images, targets = cutmix_or_mixup(images, targets)\n",
    "    \n",
    "    # 3. å°†åŸå§‹çš„æ–‡ä»¶ååˆ—è¡¨å’Œç»è¿‡å¢å¼ºå¤„ç†çš„å›¾åƒã€æ ‡ç­¾é‡æ–°ç»„åˆå¹¶è¿”å›\n",
    "    return filenames, images, targets\n",
    "    \n",
    "def image_transform(mean,std):\n",
    "    args = KaggleConfig()\n",
    "    if args.aug_methon == 0:\n",
    "        train_transform = A.Compose([\n",
    "            # --- æ ¸å¿ƒç­–ç•¥ï¼šç­‰æ¯”ä¾‹æ”¾å¤§ + ä¸­å¿ƒè£å‰ª ---\n",
    "            # è¿™ä¸€æ­¥å®Œå…¨ç­‰æ•ˆäº torchvision çš„ transforms.Resize(int(224 * 1.14))\n",
    "            # å®ƒå°†å›¾åƒçš„æœ€çŸ­è¾¹ç¼©æ”¾åˆ° 255 (å³ 224 * 1.14)ï¼ŒåŒæ—¶ä¿æŒé•¿å®½æ¯”ã€‚\n",
    "            A.SmallestMaxSize(max_size=int(224 * 1.14)), \n",
    "    \n",
    "            # è¿™ä¸€æ­¥ç­‰æ•ˆäº transforms.CenterCrop(224)\n",
    "            A.CenterCrop(height=224, width=224),\n",
    "    \n",
    "             # --- å…¶ä»–æœ‰æ•ˆçš„å¢å¼ºæŠ€æœ¯ ---\n",
    "            # æ°´å¹³ç¿»è½¬\n",
    "            A.HorizontalFlip(p=0.5), \n",
    "        \n",
    "            # è½»å¾®çš„å‡ ä½•å˜æ¢ (ä½ç§»ã€ç¼©æ”¾ã€æ—‹è½¬)ï¼Œå¯¹GPRå›¾åƒçš„ç»†å¾®å˜åŒ–å¾ˆæœ‰æ•ˆ\n",
    "            A.ShiftScaleRotate(shift_limit=0.06, scale_limit=0.1, rotate_limit=5, p=0.7),\n",
    "\n",
    "            # æ¨¡æ‹Ÿä¿¡å·å¼ºåº¦çš„å˜åŒ–\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n",
    "    \n",
    "            # å¢å¼ºå¯¹å™ªå£°çš„æŠµæŠ—åŠ›\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n",
    "\n",
    "            # éšæœºé®æŒ¡ï¼Œå¼ºè¿«æ¨¡å‹å…³æ³¨å…¨å±€ç‰¹å¾\n",
    "            #A.CoarseDropout(max_holes=8, max_height=20, max_width=20, p=0.5),\n",
    "    \n",
    "            # æ ‡å‡†åŒ–å’Œç±»å‹è½¬æ¢\n",
    "            A.Normalize(mean, std),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "             # 2. éªŒè¯å’Œæµ‹è¯•é›†çš„é¢„å¤„ç† (åŒæ ·ä¿æŒæœ€çŸ­è¾¹ç¼©æ”¾ï¼Œä¿è¯å¤„ç†é€»è¾‘ä¸€è‡´æ€§)\n",
    "        val_test_transform = A.Compose([\n",
    "            A.SmallestMaxSize(max_size=int(224 * 1.14)),\n",
    "            A.CenterCrop(height=224, width=224),\n",
    "            A.Normalize(mean,std),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    elif args.aug_methon == 1:\n",
    "        train_transform = A.Compose([\n",
    "        # --- å°ºå¯¸ä¸å‡ ä½•å˜æ¢ ---\n",
    "        # æ­¥éª¤ 1: ä½¿ç”¨ RandomResizedCrop æ›¿ä»£åŸæ¥çš„å›ºå®šç¼©æ”¾å’Œä¸­å¿ƒè£å‰ªã€‚\n",
    "        # è¿™æ˜¯æ›´ç°ä»£ã€æ›´å¼ºå¤§çš„è®­ç»ƒæŠ€å·§ï¼Œå®ƒéšæœºåœ°åœ¨å›¾åƒä¸­è£å‰ªä¸åŒå¤§å°å’Œé•¿å®½æ¯”çš„åŒºåŸŸï¼Œç„¶åç¼©æ”¾åˆ°224x224ã€‚\n",
    "        # è¿™èƒ½è®©æ¨¡å‹å¯¹ç›®æ ‡çš„ä½ç½®å’Œå¤§å°å˜åŒ–æ›´åŠ é²æ£’ã€‚\n",
    "        A.LongestMaxSize(max_size=224, p=1.0),\n",
    "        A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=134, p=1.0),\n",
    "\n",
    "        # æ­¥éª¤ 2: æ°´å¹³ç¿»è½¬ï¼Œå¯¹äºGPRæ•°æ®æ˜¯å®‰å…¨ä¸”æœ‰æ•ˆçš„å¢å¼ºã€‚\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "\n",
    "        # æ­¥éª¤ 3: å¼¹æ€§å˜æ¢ï¼Œæ¨¡æ‹Ÿåœ°ä¸‹ä»‹è´¨ä¸å‡åŒ€å¯¼è‡´çš„æ³¢å½¢è½»å¾®æ‰­æ›²ï¼Œå¯¹GPRæ•°æ®éå¸¸æœ‰æ•ˆã€‚\n",
    "        A.ElasticTransform(p=0.5, alpha=20, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.05,      # è½»å¾®å¹³ç§» (Â±5%)\n",
    "            scale_limit=0.1,       # è½»å¾®ç¼©æ”¾ (Â±10%)\n",
    "            rotate_limit=0,        # âŒ GPRæ•°æ®ä¸åº”æ—‹è½¬!\n",
    "            border_mode=0,         # é»‘è‰²å¡«å……\n",
    "            p=0.3                  # é™ä½æ¦‚ç‡,é¿å…è¿‡åº¦å˜æ¢\n",
    "        ),\n",
    "        # --- å™ªå£°ä¸é®æŒ¡ç»„åˆ ---\n",
    "        # æ­¥éª¤ 4: ä½¿ç”¨ SomeOf ç»„åˆå™¨ï¼Œæ¯æ¬¡ä»¥80%çš„æ¦‚ç‡ä»ä»¥ä¸‹ä¸‰ç§å™ªå£°/é®æŒ¡ä¸­éšæœºé€‰æ‹©ä¸¤ç§æ¥åº”ç”¨ã€‚\n",
    "        # è¿™æå¤§åœ°å¢åŠ äº†æ•°æ®çš„å¤šæ ·æ€§ï¼Œé¿å…æ¨¡å‹å¯¹æŸç§ç‰¹å®šå™ªå£°äº§ç”Ÿè¿‡æ‹Ÿåˆã€‚\n",
    "        A.OneOf([\n",
    "            # é€‰é¡¹1: é«˜æ–¯å™ªå£° - æ¨¡æ‹Ÿä¼ æ„Ÿå™¨çš„éšæœºå™ªå£°\n",
    "            A.GaussNoise(var_limit=(5.0, 30.0), p=1.0),  # âœ… é™ä½å™ªå£°å¼ºåº¦: 10~50 -> 5~30\n",
    "            \n",
    "            # é€‰é¡¹2: å°èŒƒå›´éšæœºé®æŒ¡ - æ¨¡æ‹Ÿæ•°æ®ç¼ºå¤±\n",
    "            A.CoarseDropout(\n",
    "                max_holes=4,           # âœ… å‡å°‘é®æŒ¡å—æ•°é‡: 8 -> 4\n",
    "                max_height=15,         # âœ… å‡å°é®æŒ¡å°ºå¯¸: 25 -> 15\n",
    "                max_width=15, \n",
    "                min_holes=2,           # âœ… å‡å°‘æœ€å°é®æŒ¡æ•°: 4 -> 2\n",
    "                fill_value=0, \n",
    "                p=1.0\n",
    "            ),\n",
    "            \n",
    "            # é€‰é¡¹3: ä¹˜æ€§å™ªå£° - æ¨¡æ‹Ÿä¿¡å·å¢ç›Šå˜åŒ–\n",
    "            A.MultiplicativeNoise(multiplier=[0.9, 1.1], p=1.0),  # âœ… æ”¶çª„èŒƒå›´: 0.8~1.2 -> 0.9~1.1\n",
    "        ], p=0.4),  # âœ… æé«˜åº”ç”¨æ¦‚ç‡: 0.3 -> 0.4 (å› ä¸ºç°åœ¨åªé€‰ä¸€ç§,ä¸ä¼šå åŠ \n",
    "\n",
    "        # --- ä¿¡å·å¼ºåº¦ä¸é¢œè‰²å˜æ¢ ---\n",
    "        # æ­¥éª¤ 5: éšæœºè°ƒæ•´äº®åº¦å’Œå¯¹æ¯”åº¦ï¼Œæ¨¡æ‹Ÿä¿¡å·å¼ºåº¦çš„å˜åŒ–ã€‚\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=0.15,  # âœ… é™ä½å¼ºåº¦: 0.2 -> 0.15\n",
    "            contrast_limit=0.15, \n",
    "            p=0.5                   # âœ… é™ä½æ¦‚ç‡: 0.7 -> 0.5\n",
    "        ),\n",
    "\n",
    "        # --- æ ‡å‡†åŒ–ä¸æ ¼å¼è½¬æ¢ ---\n",
    "        # æ­¥éª¤ 6: æ ‡å‡†åŒ–å’Œè½¬æ¢ä¸ºTensorï¼Œè¿™æ˜¯ä»»ä½•æ¨¡å‹éƒ½å¿…éœ€çš„æ­¥éª¤ã€‚\n",
    "        A.Normalize(mean=mean, std=std),\n",
    "        ToTensorV2(),\n",
    "        ])\n",
    "         # 2. éªŒè¯å’Œæµ‹è¯•é›†çš„é¢„å¤„ç† (åŒæ ·ä¿æŒæœ€çŸ­è¾¹ç¼©æ”¾ï¼Œä¿è¯å¤„ç†é€»è¾‘ä¸€è‡´æ€§)\n",
    "        val_test_transform = A.Compose([\n",
    "            A.LongestMaxSize(max_size=224, p=1.0),\n",
    "            A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=134, p=1.0),\n",
    "            A.Normalize(mean,std),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    return(train_transform ,val_test_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db62f5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T06:06:19.783157Z",
     "iopub.status.busy": "2025-11-15T06:06:19.782687Z",
     "iopub.status.idle": "2025-11-15T06:06:19.789554Z",
     "shell.execute_reply": "2025-11-15T06:06:19.789034Z"
    },
    "papermill": {
     "duration": 0.033641,
     "end_time": "2025-11-15T06:06:19.790516",
     "exception": false,
     "start_time": "2025-11-15T06:06:19.756875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# å®šä¹‰å…¨å±€ç±»åˆ«æ˜ å°„å’Œåç§°åˆ—è¡¨ï¼Œæ–¹ä¾¿åç»­ä½¿ç”¨\n",
    "CLASS_MAP = {\n",
    "    'Crack': 0, 'Loose': 1,\n",
    "    'Mud Pumping': 2, 'Pipeline': 3, 'Redar': 4, 'Void': 5,\n",
    "     'Water Abnormality': 6, 'stell_rib': 7 \n",
    "\n",
    "}\n",
    "CLASS_NAMES = [name for name, idx in sorted(CLASS_MAP.items(), key=lambda item: item[1])]\n",
    "\n",
    "# æ–°çš„ DatasetImage ç±»ï¼Œä½¿ç”¨ albumentations\n",
    "class DatasetImage(Dataset):\n",
    "    def __init__(self, file_names, transform=None):\n",
    "        self.file_names = file_names\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file_name = self.file_names[idx]\n",
    "        # è¯»å–å›¾åƒ (Albumentations éœ€è¦ RGB æ ¼å¼)\n",
    "        image = cv2.imread(img_file_name)\n",
    "        if image is None: raise ValueError(f\"æ— æ³•è¯»å–å›¾åƒ: {img_file_name}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # åº”ç”¨å¢å¼º\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        # è·å–æ ‡ç­¾\n",
    "        class_name = os.path.basename(os.path.dirname(img_file_name))\n",
    "        cls = torch.tensor(CLASS_MAP[class_name], dtype=torch.long)\n",
    "        \n",
    "        return img_file_name, image, cls\n",
    "\n",
    "# KaggleTestDataset ä¿æŒä¸å˜...\n",
    "class KaggleTestDataset(Dataset):\n",
    "    def __init__(self, file_paths, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return os.path.basename(img_path), img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a11dfe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T06:06:19.841721Z",
     "iopub.status.busy": "2025-11-15T06:06:19.841495Z",
     "iopub.status.idle": "2025-11-15T06:06:19.846317Z",
     "shell.execute_reply": "2025-11-15T06:06:19.845591Z"
    },
    "papermill": {
     "duration": 0.031904,
     "end_time": "2025-11-15T06:06:19.847342",
     "exception": false,
     "start_time": "2025-11-15T06:06:19.815438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def my_get_encoder(name, num_classes=1, pretrained=True, drop_rate=0.0): # 1. æ–°å¢ drop_rate å‚æ•°\n",
    "    # 2. åœ¨åˆ›å»ºæ¨¡å‹æ—¶ï¼Œå°† drop_rate ä¼ é€’ç»™ timm\n",
    "    #    timm ä¼šè‡ªåŠ¨å°†å…¶åº”ç”¨åˆ°æ¨¡å‹çš„åˆ†ç±»å¤´\n",
    "    encoder = timm.create_model(name, pretrained=pretrained, num_classes=num_classes, drop_rate=drop_rate)\n",
    "    return encoder\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    # 3. åœ¨åˆå§‹åŒ–æ—¶æ¥æ”¶ drop_rate\n",
    "    def __init__(self, encoder, classnum, pretrained=True, drop_rate=0.0): \n",
    "        super().__init__()\n",
    "        # 4. å°† drop_rate ä¼ é€’ä¸‹å»\n",
    "        self.clf_model = my_get_encoder(encoder, num_classes=classnum, pretrained=pretrained, drop_rate=drop_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.clf_model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a03a8a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T06:06:19.898786Z",
     "iopub.status.busy": "2025-11-15T06:06:19.898530Z",
     "iopub.status.idle": "2025-11-15T06:06:19.917019Z",
     "shell.execute_reply": "2025-11-15T06:06:19.916271Z"
    },
    "papermill": {
     "duration": 0.045669,
     "end_time": "2025-11-15T06:06:19.918144",
     "exception": false,
     "start_time": "2025-11-15T06:06:19.872475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _calculate_metrics(metrics, mode, compute_cm):\n",
    "    # --- è®¡ç®—æ•´ä½“æŒ‡æ ‡ ---\n",
    "    precision = precision_score(metrics['all_targets'], metrics['all_preds'], average='weighted', zero_division=0)\n",
    "    recall = recall_score(metrics['all_targets'], metrics['all_preds'], average='weighted', zero_division=0)\n",
    "    f1 = f1_score(metrics['all_targets'], metrics['all_preds'], average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(metrics['all_targets'], metrics['all_preds'], average='weighted', zero_division=0)\n",
    "    f1_macro = f1_score(metrics['all_targets'], metrics['all_preds'], average='macro', zero_division=0) # <--- æ·»åŠ è¿™ä¸€è¡Œ\n",
    "    # auc_macro, auc_weighted = 0.0, 0.0\n",
    "    auc_macro, auc_weighted = 0.0, 0.0\n",
    "    try:\n",
    "        auc_macro = roc_auc_score(metrics['all_targets'], metrics['all_probs'], multi_class='ovr', average='macro')\n",
    "        auc_weighted = roc_auc_score(metrics['all_targets'], metrics['all_probs'], multi_class='ovr', average='weighted')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"AUCè®¡ç®—å¤±è´¥: {e}\")\n",
    "\n",
    "    # --- è®¡ç®—æ··æ·†çŸ©é˜µå’Œå„ç±»åˆ«æŒ‡æ ‡ ---\n",
    "    cm = confusion_matrix(metrics['all_targets'], metrics['all_preds']) if compute_cm and (mode in ['test', 'val']) else None\n",
    "    per_class_recall = None\n",
    "    per_class_precision = None\n",
    "    if cm is not None:\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            # å„ç±»åˆ«å¬å›ç‡(Recall) = å¯¹è§’çº¿å…ƒç´  / å¯¹åº”è¡Œçš„æ€»å’Œ\n",
    "            # è¿™ä¹Ÿç­‰åŒäºè¯¥ç±»åˆ«çš„å‡†ç¡®ç‡ (True Positive Rate)\n",
    "            per_class_recall = cm.diagonal() / cm.sum(axis=1)\n",
    "            per_class_recall[np.isnan(per_class_recall)] = 0\n",
    "\n",
    "            # å„ç±»åˆ«ç²¾ç¡®ç‡(Precision) = å¯¹è§’çº¿å…ƒç´  / å¯¹åº”åˆ—çš„æ€»å’Œ\n",
    "            per_class_precision = cm.diagonal() / cm.sum(axis=0)\n",
    "            per_class_precision[np.isnan(per_class_precision)] = 0\n",
    "\n",
    "    return {\n",
    "        'loss': metrics['loss'].avg, 'accuracy': metrics['accuracy'].avg,\n",
    "        'precision': precision, 'recall': recall, 'f1': f1_weighted, 'f1_macro': f1_macro, # <--- ä¿®æ”¹è¿™ä¸€è¡Œ\n",
    "        'auc_macro': auc_macro, 'auc_weighted': auc_weighted,\n",
    "        'confusion_matrix': cm,\n",
    "        'per_class_recall': per_class_recall,\n",
    "        'per_class_precision': per_class_precision\n",
    "    }\n",
    "\n",
    "\n",
    "def run_epoch(mode, model, data_loader, criterion, device, epoch, optimizer=None, writer=None, compute_cm=False, args=None):\n",
    "    is_training = (mode == 'train')\n",
    "    model.train() if is_training else model.eval()\n",
    "    torch.set_grad_enabled(is_training)\n",
    "    metrics = {'loss': AverageMeter(\"Loss\", \".16f\"), 'accuracy': AverageMeter(\"Acc\", \".8f\"), 'all_preds': [], 'all_targets': [], 'all_probs': []}\n",
    "    pbar = tqdm(data_loader, desc=f\"{mode.capitalize()} Epoch {epoch}\")\n",
    "    inference_start_time = time.time()   #è®°å½•æ—¶é—´\n",
    "    \n",
    "    # ğŸ”¥ ä¿®å¤: å¦‚æœæ²¡æœ‰ä¼ å…¥ args,å°±åˆ›å»ºä¸€ä¸ªé»˜è®¤çš„\n",
    "    if args is None:\n",
    "        args = KaggleConfig()\n",
    "    \n",
    "    for _, (file_name, images, target) in enumerate(pbar):\n",
    "        images, target = images.to(device), target.to(device)\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        probs = torch.softmax(output, dim=1).detach().cpu().numpy()\n",
    "        preds = output.argmax(dim=1).cpu().numpy()\n",
    "        # -- æ ¸å¿ƒä¿®æ­£ï¼šç»Ÿä¸€å¤„ç†ç¡¬æ ‡ç­¾å’Œè½¯æ ‡ç­¾ --\n",
    "        if args.use_hybrid_mix and target.ndim == 2:\n",
    "            # å¯¹äºè½¯æ ‡ç­¾ï¼Œå– argmax å¾—åˆ°æ•´æ•°æ ‡ç­¾ç”¨äºè®¡ç®—æŒ‡æ ‡\n",
    "            true_labels_for_metrics = target.argmax(dim=1)\n",
    "        else:\n",
    "            # å¯¹äºç¡¬æ ‡ç­¾ï¼Œç›´æ¥ä½¿ç”¨\n",
    "            true_labels_for_metrics = target\n",
    "\n",
    "        # ä½¿ç”¨ä¿®æ­£åçš„ true_labels_for_metrics æ¥ä¿å­˜å’Œè®¡ç®—\n",
    "        metrics['all_probs'].extend(probs);\n",
    "        metrics['all_preds'].extend(preds); \n",
    "        #metrics['all_targets'].extend(target.cpu().numpy())\n",
    "        metrics['loss'].update(loss.item(), images.size(0))\n",
    "        metrics['all_targets'].extend(true_labels_for_metrics.cpu().numpy())\n",
    "        #metrics['accuracy'].update((preds == target.cpu().numpy()).mean(), images.size(0))\n",
    "        # å°†è¿™ä¸€è¡Œ:\n",
    "        # metrics['accuracy'].update((preds == target.cpu().numpy()).mean(), images.size(0))\n",
    "        # æ›¿æ¢ä¸ºä¸‹é¢è¿™ä¸ªä»£ç å—:\n",
    "        if args.use_hybrid_mix and target.ndim == 2:\n",
    "            # å¯¹äºCutMix/MixUpç”Ÿæˆçš„è½¯æ ‡ç­¾(2D)ï¼Œæ¯”è¾ƒå®ƒä»¬çš„argmax\n",
    "            true_labels = target.argmax(dim=1)\n",
    "        else:\n",
    "            # å¯¹äºæ™®é€šçš„ç¡¬æ ‡ç­¾(1D)\n",
    "            true_labels = target\n",
    "        metrics['accuracy'].update((preds == true_labels.cpu().numpy()).mean(), images.size(0))\n",
    "        pbar.set_description(f\"{mode:5} | Loss:{metrics['loss'].avg:.3f} Acc:{metrics['accuracy'].avg:.2%}\")\n",
    "    \n",
    "    inference_end_time = time.time()\n",
    "    final_metrics = _calculate_metrics(metrics, mode, compute_cm)\n",
    "\n",
    "    # --- å†™å…¥TensorBoardæ—¥å¿— ---\n",
    "    if writer:\n",
    "        prefix = f\"{mode}/\"\n",
    "        writer.add_scalar(f'{prefix}loss', final_metrics['loss'], epoch)\n",
    "        writer.add_scalar(f'{prefix}accuracy', final_metrics['accuracy'], epoch)\n",
    "        writer.add_scalar(f'{prefix}precision_weighted', final_metrics['precision'], epoch)\n",
    "        writer.add_scalar(f'{prefix}recall_weighted', final_metrics['recall'], epoch)\n",
    "        writer.add_scalar(f'{prefix}f1_weighted', final_metrics['f1'], epoch)\n",
    "        writer.add_scalar(f'{prefix}f1_macro', final_metrics['f1_macro'], epoch) # <--- æ·»åŠ è¿™ä¸€è¡Œ\n",
    "        #writer.add_scalar(f'{prefix}auc_macro', final_metrics['auc_macro'], epoch)\n",
    "        writer.add_scalar(f'{prefix}auc_macro', final_metrics['auc_macro'], epoch)\n",
    "        writer.add_scalar(f'{prefix}auc_weighted', final_metrics['auc_weighted'], epoch)\n",
    "\n",
    "        # å†™å…¥æ··æ·†çŸ©é˜µå›¾\n",
    "        if final_metrics.get('confusion_matrix') is not None and mode in ['val', 'test']:\n",
    "            writer.add_image(f'{prefix}confusion_matrix', cm_to_figure(final_metrics['confusion_matrix']), epoch)\n",
    "\n",
    "        # (æ–°å¢) å†™å…¥å„ç±»åˆ«æŒ‡æ ‡\n",
    "        if mode == 'test':\n",
    "            \n",
    "            report = classification_report(metrics['all_targets'], metrics['all_preds'], target_names=CLASS_NAMES, output_dict=True, zero_division=0)\n",
    "            \n",
    "            for class_name, class_metrics in report.items():\n",
    "                if isinstance(class_metrics, dict): # ç¡®ä¿åªå¤„ç†ç±»åˆ«è¡Œ\n",
    "                    writer.add_scalar(f'{prefix}{class_name}/precision', class_metrics['precision'], epoch)\n",
    "                    writer.add_scalar(f'{prefix}{class_name}/recall', class_metrics['recall'], epoch)\n",
    "                    writer.add_scalar(f'{prefix}{class_name}/f1-score', class_metrics['f1-score'], epoch)\n",
    "                    writer.add_scalar(f'{prefix}{class_name}/support', class_metrics['support'], epoch)\n",
    "            logging.info(\"å·²å°†æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†æµ‹è¯•æŒ‡æ ‡å†™å…¥TensorBoardã€‚\")\n",
    "\n",
    "    \n",
    "    # ä¿®æ­£äº†è¿™é‡Œçš„å˜é‡åï¼šfinal_files -> final_metrics\n",
    "    log_message = (f\"{mode.capitalize()} Results - Loss: {final_metrics['loss']:.4f} | \"\n",
    "               f\"Accuracy: {final_metrics['accuracy']:.4%} | \"\n",
    "               f\"F1_weighted: {final_metrics['f1']:.4%} | \"\n",
    "               f\"F1_macro: {final_metrics['f1_macro']:.4%}\")\n",
    "    if mode == 'test':\n",
    "        total_inference_time = inference_end_time - inference_start_time\n",
    "        num_samples = len(data_loader.dataset)\n",
    "        fps = num_samples / total_inference_time\n",
    "        log_message += f\" | Inference Speed: {fps:.2f} FPS\"\n",
    "        logging.info(f\"æ€»æ¨ç†æ—¶é—´ (Total Inference Time): {total_inference_time:.2f} seconds for {num_samples} images.\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"âœ… æ€»æ¨ç†æ—¶é—´ (Total Inference Time): {total_inference_time:.2f} seconds for {num_samples} images.\")\n",
    "        print(f\"âœ… æ¨ç†é€Ÿåº¦ (Inference Speed): {fps:.2f} FPS\")\n",
    "        print(log_message) # ä¹Ÿç”¨ print è¾“å‡ºæœ€ç»ˆæŒ‡æ ‡\n",
    "        print(\"-\" * 50)\n",
    "    logging.info(log_message)\n",
    "    \n",
    "    # ğŸ”¥ ä¿®å¤: ä»ä¼ å…¥çš„ args è·å– run_id\n",
    "    encoder_lr = getattr(args, 'run_id', None)\n",
    "    save_metrics_to_excel(f\"{mode}_metrics.xlsx\", epoch, encoder_lr=encoder_lr, **final_metrics)\n",
    "    return final_metrics\n",
    "\n",
    "\n",
    "def predict_on_test(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_filenames, all_predictions = [], []\n",
    "    with torch.no_grad():\n",
    "        for filenames, images in tqdm(data_loader, desc=\"Predicting\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            all_filenames.extend(filenames)\n",
    "            all_predictions.extend(preds)\n",
    "    return all_filenames, all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c54def68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T06:06:19.969255Z",
     "iopub.status.busy": "2025-11-15T06:06:19.968985Z",
     "iopub.status.idle": "2025-11-15T06:06:19.974037Z",
     "shell.execute_reply": "2025-11-15T06:06:19.973262Z"
    },
    "papermill": {
     "duration": 0.032046,
     "end_time": "2025-11-15T06:06:19.975176",
     "exception": false,
     "start_time": "2025-11-15T06:06:19.943130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_scheduler(optimizer, phase, args, num_epochs_stage1=None):\n",
    "    \"\"\"\n",
    "    phase: \"stage1\" æˆ– \"stage2\"\n",
    "    num_epochs_stage1: é˜¶æ®µä¸€çš„è®­ç»ƒè½®æ•°ï¼ˆä»…ç”¨äºè®¡ç®— stage2 çš„ T_maxï¼‰\n",
    "    \"\"\"\n",
    "    if args.lr_scheduler == \"cosine\":\n",
    "        if phase == \"stage1\":\n",
    "            return torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, T_max=args.stage1_tmax, eta_min=args.min_lr\n",
    "            )\n",
    "        else:  # stage2\n",
    "            # æ ¹æ®æ€» epoch è‡ªåŠ¨è®¡ç®—é˜¶æ®µäºŒçš„ T_max\n",
    "            tmax_stage2 = args.num_epochs - (num_epochs_stage1 or 0)\n",
    "            return torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, T_max=tmax_stage2, eta_min=args.min_lr\n",
    "            )\n",
    "    else:  # \"plateau\"\n",
    "        # æ³¨æ„ï¼šPlateau çš„ step éœ€è¦ä¼ å…¥éªŒè¯æŸå¤±ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒå¾ªç¯é‡Œå¤„ç†\n",
    "        return torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode=\"min\",\n",
    "            factor=args.plateau_factor,\n",
    "            patience=args.plateau_patience,\n",
    "            min_lr=args.min_lr,\n",
    "            verbose=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# ğŸ†• KæŠ˜äº¤å‰éªŒè¯è®­ç»ƒè„šæœ¬ (æœ€å°æ”¹åŠ¨ç‰ˆ - å¤ç”¨mainå‡½æ•°)\n",
    "# =====================================================================\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def get_kfold_splits(file_names, n_folds=5, random_state=42):\n",
    "    \"\"\"åˆ›å»ºKæŠ˜äº¤å‰éªŒè¯çš„æ•°æ®åˆ†å‰²\"\"\"\n",
    "    labels = [CLASS_MAP[os.path.basename(os.path.dirname(p))] for p in file_names]\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    fold_splits = []\n",
    "    for train_idx, val_idx in skf.split(file_names, labels):\n",
    "        fold_splits.append((train_idx, val_idx))\n",
    "    return fold_splits\n",
    "\n",
    "\n",
    "def generate_dataset(train_file_names, val_file_names, test_file_names, batch_size, val_batch_size, test_batch_size, train_transform, val_test_transform):\n",
    "    \"\"\"ç”Ÿæˆæ•°æ®åŠ è½½å™¨\"\"\"\n",
    "    train_dataset = DatasetImage(train_file_names, transform=train_transform)\n",
    "    valid_dataset = DatasetImage(val_file_names, transform=val_test_transform)\n",
    "    test_dataset = DatasetImage(test_file_names, transform=val_test_transform)\n",
    "    \n",
    "    args = KaggleConfig()\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        num_workers=2, \n",
    "        shuffle=True, \n",
    "        drop_last=True,\n",
    "        collate_fn=collate_fn if args.use_hybrid_mix else default_collate\n",
    "    )\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=val_batch_size, num_workers=2, shuffle=False, drop_last=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, num_workers=2, shuffle=False, drop_last=False)\n",
    "    \n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "\n",
    "def main(args, device, train_file_names, val_file_names, test_file_names):\n",
    "    \"\"\"ä¸»è®­ç»ƒå‡½æ•° (å·²ä¿®æ”¹ä¸ºæ¥æ”¶æ–‡ä»¶åˆ—è¡¨)\"\"\"\n",
    "    \n",
    "    print(f\"æ‰¾åˆ° {len(train_file_names)} ä¸ªè®­ç»ƒæ–‡ä»¶, {len(val_file_names)} ä¸ªéªŒè¯æ–‡ä»¶, {len(test_file_names)} ä¸ªæµ‹è¯•æ–‡ä»¶\")\n",
    "    \n",
    "    # --- è®¡ç®—å‡å€¼æ ‡å‡†å·®å’Œæ•°æ®å¢å¼º ---\n",
    "    train_mean, train_std = mean_and_std(train_file_names)\n",
    "    train_transform, val_test_transform = image_transform(mean=train_mean, std=train_std)\n",
    "    \n",
    "    train_loader, valid_loader, test_loader = generate_dataset(\n",
    "        train_file_names, val_file_names, test_file_names,\n",
    "        args.train_batch_size, args.val_batch_size, args.test_batch_size,\n",
    "        train_transform=train_transform,\n",
    "        val_test_transform=val_test_transform\n",
    "    )\n",
    "    \n",
    "    # --- è®¡ç®—ç±»åˆ«æƒé‡ ---\n",
    "    print(\"æ­£åœ¨è®¡ç®—ç±»åˆ«æƒé‡ä»¥å¤„ç†æ•°æ®ä¸å¹³è¡¡é—®é¢˜...\")\n",
    "    train_labels = [CLASS_MAP[os.path.basename(os.path.dirname(p))] for p in train_file_names]\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    print(f\"è®¡ç®—å‡ºçš„ç±»åˆ«æƒé‡: {class_weights.cpu().numpy()}\")\n",
    "    \n",
    "    # --- åˆå§‹åŒ–æ¨¡å‹ ---\n",
    "    print(f\"\\næ­£åœ¨åˆå§‹åŒ–æ¨¡å‹: {args.encoder}\")\n",
    "    model = ClassificationModel(encoder=args.encoder, classnum=args.classnum, pretrained=True, drop_rate=args.dropout_rate).to(device)\n",
    "    \n",
    "    model_for_profiling = deepcopy(model)\n",
    "    model_for_profiling.eval()\n",
    "    num_params = count_parameters(model)\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"âœ… æ¨¡å‹å‚æ•°é‡ (Parameters): {num_params / 1e6:.2f} M\")\n",
    "    logging.info(\"==================== MODEL EFFICIENCY ====================\")\n",
    "    logging.info(f\"æ¨¡å‹å‚æ•°é‡ (Parameters): {num_params / 1e6:.2f} M\")\n",
    "    dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "    flops, params = profile(model_for_profiling, inputs=(dummy_input,))\n",
    "    print(f\"âœ… FLOPs: {flops / 1e9:.2f} G\")\n",
    "    print(\"=\" * 60)\n",
    "    logging.info(f\"FLOPs: {flops / 1e9:.2f} G\")\n",
    "    logging.info(\"==========================================================\")\n",
    "    del model_for_profiling\n",
    "    \n",
    "    # --- æŸå¤±å‡½æ•° ---\n",
    "    if args.use_hybrid_mix:\n",
    "        print(\"æ­£åœ¨ä½¿ç”¨ nn.CrossEntropyLoss (å› ä¸ºå¯ç”¨äº† CutMix/MixUp)\")\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=args.label_smoothing, weight=class_weights)\n",
    "    else:\n",
    "        print(\"æ­£åœ¨ä½¿ç”¨ FocalLoss\")\n",
    "        criterion = FocalLoss(alpha=class_weights, gamma=args.focal_loss_gamma)\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=args.save_path)\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    # =====================================================================================\n",
    "    # é˜¶æ®µä¸€: å†»ç»“ä¸»å¹²ç½‘ç»œï¼Œåªè®­ç»ƒåˆ†ç±»å¤´\n",
    "    # =====================================================================================\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ”¥ é˜¶æ®µä¸€: å†»ç»“ä¸»å¹²ç½‘ç»œï¼Œåªè®­ç»ƒåˆ†ç±»å¤´\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for param in model.clf_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    if hasattr(model.clf_model, 'head'):\n",
    "        for param in model.clf_model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(\"æ¨¡å‹ä¸»å¹²å·²å†»ç»“ï¼Œåªè®­ç»ƒæœ€åçš„ 'head' å±‚ã€‚\")\n",
    "    elif hasattr(model.clf_model, 'classifier'):\n",
    "        for param in model.clf_model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(\"æ¨¡å‹ä¸»å¹²å·²å†»ç»“ï¼Œåªè®­ç»ƒæœ€åçš„ 'classifier' å±‚ã€‚\")\n",
    "    elif hasattr(model.clf_model, 'fc'):\n",
    "        for param in model.clf_model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(\"æ¨¡å‹ä¸»å¹²å·²å†»ç»“ï¼Œåªè®­ç»ƒæœ€åçš„ 'fc' å±‚ã€‚\")\n",
    "    else:\n",
    "        raise AttributeError(\"æ— æ³•åœ¨æ¨¡å‹ä¸­æ‰¾åˆ° 'head', 'classifier' æˆ– 'fc' å±‚è¿›è¡Œè§£å†»ã€‚\")\n",
    "    \n",
    "    num_epochs_stage1 = 15\n",
    "    optimizer_stage1 = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.LR_head, weight_decay=args.WE_dec)\n",
    "    scheduler_stage1 = build_scheduler(optimizer_stage1, phase=\"stage1\", args=args)\n",
    "    \n",
    "    best_acc_stage1 = 0\n",
    "    for epoch in range(1, num_epochs_stage1 + 1):\n",
    "        logging.info(f\"é˜¶æ®µä¸€ - Epoch {epoch}/{num_epochs_stage1}\")\n",
    "        run_epoch('train', model, train_loader, criterion, device, epoch, optimizer=optimizer_stage1, writer=writer, args=args)\n",
    "        val_metrics = run_epoch('val', model, valid_loader, criterion, device, epoch, writer=writer, args=args)\n",
    "        \n",
    "        if args.lr_scheduler == \"cosine\":\n",
    "            scheduler_stage1.step()\n",
    "        else:\n",
    "            scheduler_stage1.step(val_metrics['loss'])\n",
    "        \n",
    "        if val_metrics['accuracy'] >= best_acc_stage1:\n",
    "            best_acc_stage1 = val_metrics['accuracy']\n",
    "            logging.info(f\"é˜¶æ®µä¸€æ–°é«˜! éªŒè¯é›†å‡†ç¡®ç‡: {best_acc_stage1:.4%}. ä¿å­˜æ¨¡å‹...\")\n",
    "            torch.save(model.state_dict(), os.path.join(args.save_path, 'best_model_stage1.pth'))\n",
    "    \n",
    "    # =====================================================================================\n",
    "    # é˜¶æ®µäºŒ: è§£å†»æ‰€æœ‰å±‚ï¼Œè¿›è¡Œå…¨å±€å¾®è°ƒ\n",
    "    # =====================================================================================\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ”¥ é˜¶æ®µäºŒ: è§£å†»æ‰€æœ‰å±‚ï¼Œè¿›è¡Œå…¨å±€å¾®è°ƒ\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"åŠ è½½é˜¶æ®µä¸€çš„æœ€ä½³æ¨¡å‹æƒé‡...\")\n",
    "    model.load_state_dict(torch.load(os.path.join(args.save_path, 'best_model_stage1.pth')))\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    print(\"æ‰€æœ‰å±‚å·²è§£å†»ã€‚\")\n",
    "    \n",
    "    optimizer_stage2 = Adam(model.parameters(), lr=args.LR_clf, weight_decay=args.WE_dec)\n",
    "    # ğŸ”¥ ä¿®å¤: ç»Ÿä¸€ä½¿ç”¨ build_schedulerï¼Œä¿æŒä¸¤é˜¶æ®µè°ƒåº¦ç­–ç•¥ä¸€è‡´\n",
    "    scheduler_stage2 = build_scheduler(optimizer_stage2, phase=\"stage2\", args=args, num_epochs_stage1=num_epochs_stage1)\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    early_stopping_patience = 35\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(num_epochs_stage1 + 1, args.num_epochs + 1):\n",
    "        logging.info(f\"é˜¶æ®µäºŒ - Epoch {epoch}/{args.num_epochs}\")\n",
    "        \n",
    "        run_epoch('train', model, train_loader, criterion, device, epoch, optimizer=optimizer_stage2, writer=writer, args=args)\n",
    "        val_metrics = run_epoch('val', model, valid_loader, criterion, device, epoch, writer=writer, args=args)\n",
    "        \n",
    "        # ğŸ”¥ ä¿®å¤: æ ¹æ®é…ç½®çš„è°ƒåº¦å™¨ç±»å‹è°ƒç”¨ä¸åŒçš„ step æ–¹æ³•\n",
    "        if args.lr_scheduler == \"cosine\":\n",
    "            scheduler_stage2.step()\n",
    "        else:\n",
    "            scheduler_stage2.step(val_metrics['loss'])\n",
    "        \n",
    "        if val_metrics['accuracy'] >= best_acc:\n",
    "            best_acc = val_metrics['accuracy']\n",
    "            best_epoch = epoch\n",
    "            epochs_no_improve = 0\n",
    "            logging.info(f\"å…¨å±€æ–°é«˜! éªŒè¯é›†å‡†ç¡®ç‡: {best_acc:.4%}. ä¿å­˜æ¨¡å‹...\")\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "            }, os.path.join(args.save_path, 'best_model.pth'))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            logging.info(f\"éªŒè¯é›†å‡†ç¡®ç‡æœªæå‡ï¼Œå½“å‰æ— æ”¹å–„è½®æ•°: {epochs_no_improve}/{early_stopping_patience}\")\n",
    "        \n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            print(f'\\n')\n",
    "            logging.info(f\"è§¦å‘æå‰åœæ­¢ï¼è¿ç»­ {early_stopping_patience} ä¸ª epochs éªŒè¯é›†å‡†ç¡®ç‡æœªæå‡ã€‚\")\n",
    "            logging.info(f\"æœ€ä½³epoch: {best_epoch}, æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.4%}\")\n",
    "            break\n",
    "    \n",
    "    training_end_time = time.time()\n",
    "    total_training_time = training_end_time - training_start_time\n",
    "    logging.info(f\"æ€»è®­ç»ƒæ—¶é—´ (Total Training Time): {total_training_time/3600:.2f} hours\")\n",
    "    \n",
    "    # --- æœ€ç»ˆæµ‹è¯•è¯„ä¼° ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"ğŸ”¥ è¯„ä¼°å…¨å±€æœ€ä½³æ¨¡å‹ (æ¥è‡ª epoch {best_epoch}ï¼ŒéªŒè¯é›†å‡†ç¡®ç‡ {best_acc:.4%})\")\n",
    "    \n",
    "    best_model_path = os.path.join(args.save_path, 'best_model.pth')\n",
    "    test_metrics = None\n",
    "    if os.path.exists(best_model_path):\n",
    "        final_test_model = ClassificationModel(encoder=args.encoder, classnum=args.classnum, pretrained=False).to(device)\n",
    "        checkpoint = torch.load(best_model_path)\n",
    "        final_test_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        test_metrics = run_epoch('test', final_test_model, test_loader, criterion, device,\n",
    "                                 epoch=checkpoint['epoch'], writer=writer, compute_cm=True, args=args)\n",
    "        \n",
    "        if test_metrics.get('confusion_matrix') is not None:\n",
    "            cm = test_metrics['confusion_matrix']\n",
    "            print(\"\\nFinal Test Confusion Matrix:\")\n",
    "            for i in range(cm.shape[0]):\n",
    "                row_str = \" | \".join([f\"{count:4d}\" for count in cm[i]])\n",
    "                print(f\"Class {i:<2} | {row_str}\")\n",
    "    \n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    torch.save(model.state_dict(), os.path.join(args.save_path, 'final_model.pth'))\n",
    "    \n",
    "    # --- ç»˜åˆ¶å†å²æ›²çº¿ ---\n",
    "    print(\"\\næ­£åœ¨ç”Ÿæˆè®­ç»ƒå†å²æ›²çº¿å›¾...\")\n",
    "    try:\n",
    "        train_metrics_df = pd.read_excel(os.path.join(args.save_path, 'train_metrics.xlsx'))\n",
    "        val_metrics_df = pd.read_excel(os.path.join(args.save_path, 'val_metrics.xlsx'))\n",
    "        history = {\n",
    "            'train_loss': train_metrics_df['Loss'].tolist(),\n",
    "            'train_acc': train_metrics_df['Accuracy'].tolist(),\n",
    "            'val_loss': val_metrics_df['Loss'].tolist(),\n",
    "            'val_acc': val_metrics_df['Accuracy'].tolist()\n",
    "        }\n",
    "        plot_history_curves(history, args.save_path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: æœªæ‰¾åˆ° train_metrics.xlsx æˆ– val_metrics.xlsxã€‚è·³è¿‡ç»˜å›¾ã€‚\")\n",
    "    except Exception as e:\n",
    "        print(f\"ç»˜å›¾æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "    \n",
    "    return {\n",
    "        'best_epoch': best_epoch,\n",
    "        'best_val_acc': best_acc,\n",
    "        'test_metrics': test_metrics\n",
    "    }\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# ä¸»è®­ç»ƒå¾ªç¯ - KæŠ˜äº¤å‰éªŒè¯\n",
    "# =====================================================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- å…¨å±€è®¾ç½® ---\n",
    "    args = KaggleConfig()\n",
    "    set_seed(42)\n",
    "    device = torch.device(f'cuda:{args.cuda_no}' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    os.makedirs(args.save_path, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ”¥ å¼€å§‹ {args.n_folds} æŠ˜äº¤å‰éªŒè¯è®­ç»ƒ\")\n",
    "    print(f\"æ¨¡å‹: {args.encoder} | å­¦ä¹ ç‡: {args.LR_clf}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # --- è·å–æ‰€æœ‰è®­ç»ƒ+éªŒè¯æ–‡ä»¶ï¼ˆåˆå¹¶ç”¨äºKæŠ˜åˆ†å‰²ï¼‰---\n",
    "    train_files = glob.glob(os.path.join(args.train_path, '*', '*.[jp][pn]g'))\n",
    "    val_files = glob.glob(os.path.join(args.val_path, '*', '*.[jp][pn]g'))\n",
    "    all_train_val_files = train_files + val_files\n",
    "    test_file_names = glob.glob(os.path.join(args.test_path, '*', '*.[jp][pn]g'))\n",
    "    \n",
    "    print(f\"æ€»è®­ç»ƒ+éªŒè¯æ–‡ä»¶æ•°: {len(all_train_val_files)}\")\n",
    "    print(f\"æµ‹è¯•æ–‡ä»¶æ•°: {len(test_file_names)}\")\n",
    "    \n",
    "    # --- åˆ›å»ºKæŠ˜åˆ†å‰² ---\n",
    "    fold_splits = get_kfold_splits(all_train_val_files, n_folds=args.n_folds, random_state=42)\n",
    "    \n",
    "    # --- å­˜å‚¨æ‰€æœ‰foldçš„ç»“æœ ---\n",
    "    all_fold_results = []\n",
    "    \n",
    "    # --- è®­ç»ƒæ¯ä¸ªfold (ğŸ†• æ”¯æŒæŒ‡å®šfoldèŒƒå›´) ---\n",
    "    for temp_idx, (train_indices, val_indices) in enumerate(fold_splits[args.start_fold:args.end_fold]):\n",
    "        fold_idx = temp_idx + args.start_fold  # è°ƒæ•´ä¸ºå®é™…çš„foldç´¢å¼•\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ğŸ”¥ å¼€å§‹è®­ç»ƒ Fold {fold_idx + 1}/{args.n_folds}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # æ ¹æ®ç´¢å¼•è·å–æ–‡ä»¶å\n",
    "        fold_train_files = [all_train_val_files[i] for i in train_indices]\n",
    "        fold_val_files = [all_train_val_files[i] for i in val_indices]\n",
    "        \n",
    "        # ğŸ”¥ è®¾ç½®å½“å‰foldçš„ä¿å­˜è·¯å¾„å’Œrun_id\n",
    "        fold_save_path = os.path.join(args.save_path, f'fold_{fold_idx}')\n",
    "        os.makedirs(fold_save_path, exist_ok=True)\n",
    "        original_save_path = args.save_path\n",
    "        args.save_path = fold_save_path\n",
    "        args.current_fold = fold_idx\n",
    "        args.run_id = f\"{args.encoder}_lr_{args.LR_clf}_fold{fold_idx}\"\n",
    "        \n",
    "        # è®­ç»ƒå½“å‰fold\n",
    "        fold_result = main(args, device, fold_train_files, fold_val_files, test_file_names)\n",
    "        fold_result['fold'] = fold_idx\n",
    "        all_fold_results.append(fold_result)\n",
    "        \n",
    "        # æ¢å¤åŸå§‹ä¿å­˜è·¯å¾„\n",
    "        args.save_path = original_save_path\n",
    "        \n",
    "        print(f\"\\nâœ… Fold {fold_idx + 1} è®­ç»ƒå®Œæˆ!\")\n",
    "        print(f\"   æœ€ä½³epoch: {fold_result['best_epoch']}\")\n",
    "        print(f\"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {fold_result['best_val_acc']:.4%}\")\n",
    "        if fold_result['test_metrics']:\n",
    "            print(f\"   æµ‹è¯•å‡†ç¡®ç‡: {fold_result['test_metrics']['accuracy']:.4%}\")\n",
    "            print(f\"   æµ‹è¯•F1 (macro): {fold_result['test_metrics']['f1_macro']:.4%}\")\n",
    "    \n",
    "    # --- æ±‡æ€»æ‰€æœ‰foldçš„ç»“æœ ---\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ‰ æ‰€æœ‰ {args.end_fold - args.start_fold} æŠ˜è®­ç»ƒå®Œæˆ!\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    avg_val_acc = np.mean([r['best_val_acc'] for r in all_fold_results])\n",
    "    std_val_acc = np.std([r['best_val_acc'] for r in all_fold_results])\n",
    "    \n",
    "    avg_test_acc = np.mean([r['test_metrics']['accuracy'] for r in all_fold_results if r['test_metrics']])\n",
    "    std_test_acc = np.std([r['test_metrics']['accuracy'] for r in all_fold_results if r['test_metrics']])\n",
    "    \n",
    "    avg_test_f1 = np.mean([r['test_metrics']['f1_macro'] for r in all_fold_results if r['test_metrics']])\n",
    "    std_test_f1 = np.std([r['test_metrics']['f1_macro'] for r in all_fold_results if r['test_metrics']])\n",
    "    \n",
    "    print(\"ğŸ“Š KæŠ˜äº¤å‰éªŒè¯æ±‡æ€»ç»“æœ:\")\n",
    "    print(f\"   éªŒè¯å‡†ç¡®ç‡: {avg_val_acc:.4%} Â± {std_val_acc:.4%}\")\n",
    "    print(f\"   æµ‹è¯•å‡†ç¡®ç‡: {avg_test_acc:.4%} Â± {std_test_acc:.4%}\")\n",
    "    print(f\"   æµ‹è¯•F1 (macro): {avg_test_f1:.4%} Â± {std_test_f1:.4%}\")\n",
    "    \n",
    "    # --- ä¿å­˜æ±‡æ€»ç»“æœ ---\n",
    "    summary_df = pd.DataFrame(all_fold_results)\n",
    "    summary_path = os.path.join(args.save_path, 'kfold_summary.csv')\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"\\nâœ… KæŠ˜æ±‡æ€»ç»“æœå·²ä¿å­˜è‡³: {summary_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7972960,
     "sourceId": 12619589,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8054472,
     "sourceId": 12741834,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8141773,
     "sourceId": 12870923,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8152888,
     "sourceId": 12886293,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8195394,
     "sourceId": 12950064,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8213083,
     "sourceId": 12976249,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8239355,
     "sourceId": 13014199,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8505203,
     "sourceId": 13402229,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8533297,
     "sourceId": 13443710,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8559815,
     "sourceId": 13482583,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8562393,
     "sourceId": 13486374,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8735355,
     "sourceId": 13729856,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8735448,
     "sourceId": 13729982,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8735465,
     "sourceId": 13730010,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8735309,
     "sourceId": 13729775,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6659.960391,
   "end_time": "2025-11-15T07:54:46.719929",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-15T06:03:46.759538",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a0cf046f48346deb884b391d001c2b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ae46debdae04b4ab411f64bc2a65e47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0a0cf046f48346deb884b391d001c2b7",
       "max": 28840352,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f2e6ce6c2e464bbe8c9cc31cee176c16",
       "tabbable": null,
       "tooltip": null,
       "value": 28840352
      }
     },
     "3f6ac595812f46b6a049f5b54d770471": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fd3f9a8fdb384bc9bd9842a19aebcbdb",
        "IPY_MODEL_2ae46debdae04b4ab411f64bc2a65e47",
        "IPY_MODEL_5d8a418059a14208a177e208a12720d1"
       ],
       "layout": "IPY_MODEL_5e33137a19ea4b74a424592e2662a068",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5037b49e29a8475b90441963cffec8a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5d8a418059a14208a177e208a12720d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b24efa3839804ae0b06589ea81f5d8e7",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_5037b49e29a8475b90441963cffec8a5",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡28.8M/28.8Mâ€‡[00:00&lt;00:00,â€‡35.2MB/s]"
      }
     },
     "5e33137a19ea4b74a424592e2662a068": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63f85c6aefe74e6e8dfe24c1c9fb38a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b24efa3839804ae0b06589ea81f5d8e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b931509331004efd81e1a3228b794425": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f2e6ce6c2e464bbe8c9cc31cee176c16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fd3f9a8fdb384bc9bd9842a19aebcbdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b931509331004efd81e1a3228b794425",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_63f85c6aefe74e6e8dfe24c1c9fb38a7",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:â€‡100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
